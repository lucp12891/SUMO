names(omic.list) <- paste0("omic", seq_len(k))
list_betas <- vector("list", k)
signal_annotation <- list(samples = assigned_indices_samples)
# NEW: store **indices** of signal features per omic/factor
feature_annotation <- vector("list", k)
names(feature_annotation) <- paste0("omic", seq_len(k))
for (omic_idx in seq_len(k)) {
n_features   <- vector_features[omic_idx]
feature_mean <- signal.features[[omic_idx]][1]
feature_sd   <- signal.features[[omic_idx]][2]
omic_data <- matrix(0, nrow = n_samples, ncol = n_features)
list_betas[[omic_idx]] <- list()
used_feature_blocks <- list()
feature_annotation[[omic_idx]] <- list()
for (factor_i in seq_len(n_factors)) {
factor_name <- paste0("factor", factor_i)
if (!(omic_idx %in% factor_omic_map[[factor_name]])) next
# Helper: sequential, non-overlapping block of feature indices
generate_sequential_feature_block <- function(available_indices,
min_percent = 0.1,
max_percent = 0.15,
used_blocks = list()) {
if (!length(available_indices)) return(integer(0))
total_features <- max(available_indices)
min_block_size <- max(5, ceiling(total_features * min_percent))
max_block_size <- min(ceiling(total_features * max_percent), length(available_indices))
if (max_block_size < min_block_size) max_block_size <- min_block_size
block_size <- sample(min_block_size:max_block_size, 1)
possible_starts <- available_indices[available_indices + block_size - 1 <= max(available_indices)]
if (!length(possible_starts)) return(integer(0))
for (start_idx in sample(possible_starts)) {
block <- start_idx:(start_idx + block_size - 1)
overlaps <- any(vapply(used_blocks, function(x) any(block %in% x), logical(1)))
if (!overlaps && all(block %in% available_indices)) return(block)
}
integer(0)
}
available_indices <- setdiff(seq_len(n_features), unlist(used_feature_blocks, use.names = FALSE))
feature_block <- generate_sequential_feature_block(available_indices, used_blocks = used_feature_blocks)
# Record indices (the annotation you want)
used_feature_blocks[[factor_name]] <- feature_block
feature_annotation[[omic_idx]][[factor_name]] <- feature_block
# Create betas and inject signal on the chosen indices
beta <- rnorm(n_features, mean = 0, sd = 0.01)
if (length(feature_block)) {
beta[feature_block] <- rnorm(length(feature_block),
mean = feature_mean + 0.5 * factor_i,
sd = feature_sd)
}
list_betas[[omic_idx]][[paste0("beta", factor_i)]] <- beta
# Add factor contribution
alpha <- list_alphas[[factor_i]]
omic_data <- omic_data + outer(alpha, beta)
}
# Always add noise
if (isTRUE(real_stats)) {
real_mean <- real_means_vars[[omic_idx]]["mean"]
real_var  <- real_means_vars[[omic_idx]]["var"]
noise_matrix <- matrix(rnorm(n_samples * n_features, mean = real_mean, sd = sqrt(real_var)),
nrow = n_samples, ncol = n_features)
signal_var <- var(as.vector(omic_data))
if (signal_var == 0) {
omic_data <- noise_matrix
} else {
scaling_factor <- sqrt((snr * real_var) / signal_var)
omic_data <- omic_data * scaling_factor + noise_matrix
}
} else {
signal_var <- var(as.vector(omic_data))
if (signal_var == 0) {
noise_matrix <- matrix(rnorm(n_samples * n_features, mean = 0, sd = 1),
nrow = n_samples, ncol = n_features)
omic_data <- noise_matrix
} else {
noise_sd <- sqrt(signal_var / snr)
noise_matrix <- matrix(rnorm(n_samples * n_features, mean = 0, sd = noise_sd),
nrow = n_samples, ncol = n_features)
omic_data <- omic_data + noise_matrix
}
colnames(omic_data) <- paste0("omic", omic_idx, "_feature_", seq_len(n_features))
rownames(omic_data) <- paste0("sample_",  seq_len(n_samples))
omic.list[[omic_idx]] <- omic_data
}
# Put the **indices** into the annotation
signal_annotation$features <- feature_annotation
# Concatenate all omics (samples x total_features)
concatenated_dataset <- do.call(cbind, omic.list)
rownames(concatenated_dataset) <- paste0("sample_", seq_len(n_samples))
# Return
list(
concatenated_datasets = list(concatenated_dataset),
omics             = omic.list,
list_alphas       = list_alphas,
list_betas        = list_betas,          # full beta vectors (for completeness)
signal_annotation = signal_annotation,    # <- **indices** per omic/factor
factor_structure  = factor_structure,
factor_map        = factor_omic_map
)
}
# Example run
sim <- sim_MultiOmics(
vector_features = c(50, 40),     # 2 omics: 50 + 40 features
n_samples       = 30,            # 30 samples
n_factors       = 2,             # 2 latent factors
snr             = 3,             # signal-to-noise ratio
signal.samples  = c(5, 1),       # mean and sd for sample-level signal
signal.features = list(
c(2, 0.1),                     # omic1: mean=2, sd=0.1
c(3, 0.2)                      # omic2: mean=3, sd=0.2
),
factor_structure = "mixed",      # factors hit random subsets of omics
num.factor       = "multiple",   # allow multiple latent factors
seed             = 123
)
View(sim)
# Example run
sim <- sim_MultiOmics(
vector_features = c(5000, 4248),     # 2 omics: 50 + 40 features
n_samples       = 200,            # 30 samples
n_factors       = 2,             # 2 latent factors
snr             = 0.5,             # signal-to-noise ratio
signal.samples  = c(1, 0.5),       # mean and sd for sample-level signal
signal.features = list(
c(2, 0.1),                     # omic1: mean=2, sd=0.1
c(3, 0.2)                      # omic2: mean=3, sd=0.2
),
factor_structure = "mixed",      # factors hit random subsets of omics
num.factor       = "multiple",   # allow multiple latent factors
seed             = 1234
)
View(sim)
sim[["signal_annotation"]][["samples"]][["factor2"]]
sim[["signal_annotation"]][["features"]][["omic1"]][["factor1"]]
devtools::document()
devtools::build()
devtools::document()
devtools::build()
View(sim)
# Example run
sim <- sim_MultiOmics(
vector_features = c(5000, 4248),     # 2 omics: 50 + 40 features
n_samples       = 200,            # 30 samples
n_factors       = 2,             # 2 latent factors
snr             = 0.5,             # signal-to-noise ratio
signal.samples  = c(1, 0.5),       # mean and sd for sample-level signal
signal.features = list(
c(2, 0.1),                     # omic1: mean=2, sd=0.1
c(3, 0.2)                      # omic2: mean=3, sd=0.2
),
factor_structure = "mixed",      # factors hit random subsets of omics
num.factor       = "multiple",   # allow multiple latent factors
seed             = 1234
)
View(sim)
sim[["signal_annotation"]][["features"]][["omic1"]][["factor1"]]
sim[["signal_annotation"]][["features"]][["omic2"]][["factor1"]]
sim[["signal_annotation"]][["features"]][["omic2"]][["factor2"]]
# Example run
sim <- simulateMultiOmics(
vector_features = c(5000, 4248),     # 2 omics: 50 + 40 features
n_samples       = 200,            # 30 samples
n_factors       = 2,             # 2 latent factors
snr             = 0.5,             # signal-to-noise ratio
signal.samples  = c(1, 0.5),       # mean and sd for sample-level signal
signal.features = list(
c(2, 0.1),                     # omic1: mean=2, sd=0.1
c(3, 0.2)                      # omic2: mean=3, sd=0.2
),
factor_structure = "mixed",      # factors hit random subsets of omics
num.factor       = "multiple",   # allow multiple latent factors
seed             = 1234
)
View(sim)
devtools::document()
devtools::build()
devtools::document()
devtools::install()
system.file("extdata", package = "SUMO")
system.file("inst/extdata", package = "SUMO")
getExportedValue("SUMO", "sumo_load_pretrained_mofa")   # should return a function
list.files(system.file("extdata", package = "SUMO"), full.names = TRUE)
list.files(system.file("inst/extdata", package = "SUMO"), full.names = TRUE)
sessionInfo()
SUMO::sumo_pretrained_mofa_available()
library(SUMO)
SUMO::sumo_pretrained_mofa_available()
devtools::build()
devtools::document()
devtools::build()
getwd()
# One-time cleanup: move files out of the wrong R/inst/ path
stopifnot(file.exists("DESCRIPTION"))  # safety: must be at package root
dir.create("inst/extdata", recursive = TRUE, showWarnings = FALSE)
if (dir.exists("R/inst/extdata")) {
moved <- file.copy(
list.files("R/inst/extdata", full.names = TRUE),
"inst/extdata",
overwrite = TRUE
)
message("Moved ", sum(moved), " file(s) into inst/extdata")
unlink("R/inst", recursive = TRUE, force = TRUE)
} else {
message("Nothing to move: 'R/inst/extdata' not found.")
}
devtools::document()
devtools::install(build_vignettes = FALSE)
list.files(system.file("extdata", package = "SUMO"), full.names = TRUE)
devtools::build9)
devtools::build()
devtools::document()
devtools::build()
devtools::document()
devtools::build()
#' Detect and configure the MOFA2 backend for SUMO
#' @return list(method = "basilisk"|"reticulate"|"pretrained",
#'              use_basilisk = TRUE/FALSE,
#'              envname = NULL|<conda env>)
#' @keywords internal
sumo_mofa_backend <- function() {
# 1) Prefer basilisk via MOFA2 if available
if (requireNamespace("MOFA2", quietly = TRUE) &&
requireNamespace("basilisk", quietly = TRUE)) {
return(list(method = "basilisk", use_basilisk = TRUE, envname = NULL))
}
# 2) Otherwise try a configured reticulate env
if (requireNamespace("reticulate", quietly = TRUE)) {
envname <- sumo_get_config("mofa_condaenv")
if (isTRUE(nzchar(envname))) {
# only select it; don't fail if missing
try(reticulate::use_condaenv(envname, required = FALSE), silent = TRUE)
if (isTRUE(try(reticulate::py_module_available("mofapy2"), silent = TRUE))) {
return(list(method = "reticulate", use_basilisk = FALSE, envname = envname))
}
# also accept already-active Python with mofapy2
if (isTRUE(try(reticulate::py_module_available("mofapy2"), silent = TRUE))) {
return(list(method = "reticulate", use_basilisk = FALSE, envname = NULL))
}
# 3) Fall back to pretrained
list(method = "pretrained", use_basilisk = FALSE, envname = NULL)
}
#' Get/set SUMO per-user configuration
#' @keywords internal
sumo_config_path <- function() {
dir <- tools::R_user_dir("SUMO", which = "config")
dir.create(dir, recursive = TRUE, showWarnings = FALSE)
file.path(dir, "config.json")
}
#' @keywords internal
sumo_get_config <- function(key, default = NULL) {
path <- sumo_config_path()
if (!file.exists(path)) return(default)
txt <- tryCatch(readLines(path, warn = FALSE), error = function(e) "")
if (!length(txt)) return(default)
cfg <- tryCatch(jsonlite::fromJSON(paste(txt, collapse = "\n")), error = function(e) NULL)
if (is.null(cfg) || is.null(cfg[[key]])) default else cfg[[key]]
}
#' @keywords internal
sumo_set_config <- function(key, value) {
path <- sumo_config_path()
cfg <- list()
if (file.exists(path)) {
old <- tryCatch(jsonlite::fromJSON(paste(readLines(path, warn = FALSE), collapse = "\n")), error = function(e) NULL)
if (is.list(old)) cfg <- old
}
cfg[[key]] <- value
writeLines(jsonlite::toJSON(cfg, auto_unbox = TRUE, pretty = TRUE), con = path, useBytes = TRUE)
invisible(TRUE)
}
#' Interactive setup for Python 'mofapy2' via reticulate (fallback when basilisk is unavailable)
#' @param envname Conda env name to create/use.
#' @param py_version Python version (use one MOFA2 is happy with, e.g. "3.10").
#' @return TRUE on success (and persists the env name in SUMO user config).
#' @export
sumo_setup_mofa <- function(envname = "r-mofa2", py_version = "3.10") {
if (!interactive()) {
message("sumo_setup_mofa() is interactive-only. See ?sumo_setup_mofa for manual steps.")
return(invisible(FALSE))
}
if (!requireNamespace("reticulate", quietly = TRUE)) {
stop("Please install.packages('reticulate') first.", call. = FALSE)
}
# Miniconda if needed
try(reticulate::install_miniconda(), silent = TRUE)
# Create env if missing
envs <- try(reticulate::conda_list()$name, silent = TRUE)
if (!isTRUE(envname %in% envs)) {
reticulate::conda_create(envname, packages = paste0("python=", py_version))
}
# Activate and install deps
reticulate::use_condaenv(envname, required = TRUE)
reticulate::py_install(c("mofapy2", "numpy", "scipy", "pandas", "h5py", "scikit-learn"),
envname = envname, pip = TRUE)
# Persist selection for future runs
sumo_set_config("mofa_condaenv", envname)
message("Configured reticulate env '", envname, "'. Future SUMO runs will auto-use it when basilisk is unavailable.")
invisible(TRUE)
}
backend <- sumo_mofa_backend()
View(backend)
if (backend$method == "reticulate" && !is.null(backend$envname)) {
# ensure the chosen env is active for the session
reticulate::use_condaenv(backend$envname, required = FALSE)
}
backend$method
# later, when calling run_mofa:
model <- run_mofa_analysis(cll, use_basilisk = identical(backend$method, "basilisk"))
# --- Training path ---
run_mofa_analysis <- function(data_list, n_factors = 2, feature_names = NULL, use_basilisk = TRUE) {
mofa_data <- if (!is.null(feature_names)) {
MOFA2::create_mofa(data_list, feature_names = feature_names)
} else {
MOFA2::create_mofa(data_list)
}
data_opts <- MOFA2::get_default_data_options(mofa_data)
data_opts$scale_views   <- FALSE
data_opts$scale_groups  <- TRUE
data_opts$center_groups <- TRUE
model_opts <- MOFA2::get_default_model_options(mofa_data)
model_opts$num_factors <- n_factors
train_opts <- MOFA2::get_default_training_options(mofa_data)
train_opts$maxiter <- 1000
train_opts$convergence_mode <- "slow"
train_opts$seed <- 123
mofa_obj <- MOFA2::prepare_mofa(
object          = mofa_data,
data_options    = data_opts,
model_options   = model_opts,
training_options= train_opts
)
outfile <- tempfile(fileext = ".hdf5")
suppressWarnings(MOFA2::run_mofa(mofa_obj, outfile, use_basilisk = use_basilisk))
}
# later, when calling run_mofa:
model <- run_mofa_analysis(cll, use_basilisk = identical(backend$method, "basilisk"))
utils::data("CLL_data", package = "MOFAdata", envir = environment())
# pick 2 views to keep the example small and fast
view_ids  <- c(2, 3)
CLL_small <- get("CLL_data", envir = environment())[view_ids]
# coerce, drop NAs, ensure row/col names exist
cll <- lapply(CLL_small, function(x) {
x <- as.matrix(x)
x[is.na(x)] <- 0
if (is.null(rownames(x))) rownames(x) <- paste0("F", seq_len(nrow(x)))
if (is.null(colnames(x))) colnames(x) <- paste0("S", seq_len(ncol(x)))
x
})
# set names ONCE, matching the two selected views
names(cll) <- names(CLL_small)
# later, when calling run_mofa:
model <- run_mofa_analysis(cll, use_basilisk = identical(backend$method, "basilisk"))
# later, when calling run_mofa:
model <- run_mofa_analysis(cll, use_basilisk = identical(backend$method, "reticulate"))
backend
devtools::document()
devtools::build()
devtools::install()
unlink(file.path("R", ".RData"), force = TRUE)
unlink(file.path("R", "MOFA_SUMO.pptx"), force = TRUE)
dir.create("inst/extdata", recursive = TRUE, showWarnings = FALSE)
file.rename("MOFA_SUMO.pptx", file.path("inst", "extdata", "MOFA_SUMO.pptx"))  # only if the file is at root
devtools::document()
dir.create("C:/R/win-library/4.3", recursive = TRUE, showWarnings = FALSE)
.libPaths(c("C:/R/win-library/4.3", .libPaths()))  # put the clean lib first
for (lib in .libPaths()) {
unlink(file.path(lib, "SUMO"), recursive = TRUE, force = TRUE)
unlink(file.path(lib, "00LOCK*"), recursive = TRUE, force = TRUE)
}
unlink(file.path("R", ".RData"), force = TRUE)
unlink(file.path("R", "MOFA_SUMO.pptx"), force = TRUE)
dir.create("inst/extdata", recursive = TRUE, showWarnings = FALSE)
stopifnot(file.exists("DESCRIPTION"))
roxygen2::roxygenise(load = "source")
devtools::document()
devtools::build()
devtools::document()
if ("SUMO" %in% loadedNamespaces()) unloadNamespace("SUMO")
dir.create("C:/R/win-library/4.3", recursive = TRUE, showWarnings = FALSE)
.libPaths("C:/R/win-library/4.3")     # IMPORTANT: replace .libPaths with ONLY this path
.libPaths()
# Remove SUMO from every library path we can think of
libs <- unique(c(.libPaths(),
file.path(Sys.getenv("LOCALAPPDATA"), "R", "win-library", "4.3"),
file.path(R.home("library"))))
for (lib in libs) {
unlink(file.path(lib, "SUMO"), recursive = TRUE, force = TRUE)
# remove any partial installs
unlink(list.files(lib, pattern = "^00LOCK.*", full.names = TRUE),
recursive = TRUE, force = TRUE)
}
stopifnot(file.exists("DESCRIPTION"))
unlink(file.path("R", ".RData"), force = TRUE)
unlink(file.path("R", "MOFA_SUMO.pptx"), force = TRUE)
dir.create("inst/extdata", recursive = TRUE, showWarnings = FALSE)
if (!requireNamespace("roxygen2", quietly = TRUE)) install.packages("roxygen2")
roxygen2::roxygenise(load = "source")
if (!requireNamespace("devtools", quietly = TRUE)) install.packages("devtools")
devtools::build()
Sys.setenv(R_BYTECODE_DISABLED = "true")
devtools::install(upgrade = "never", build_vignettes = FALSE, INSTALL_opts = "--no-multiarch")
# Minimal reporting/plots (+ optional PPTX cover slide)
generate_visuals_and_report <- function(model, data_label, export_pptx, output_name = NULL) {
MOFA2::plot_variance_explained(model, x = "group", y = "factor", plot_total = TRUE)
MOFA2::plot_factor_cor(model)
if (export_pptx) {
ppt <- officer::read_pptx()
ppt <- officer::add_slide(ppt, layout = "Title Slide", master = "Office Theme")
ppt <- officer::ph_with(
ppt, value = paste("MOFA Results -", data_label),
location = officer::ph_location_type(type = "ctrTitle")
)
ppt <- officer::ph_with(
ppt, value = paste("Generated:", Sys.Date()),
location = officer::ph_location_type(type = "subTitle")
)
outfile <- ifelse(is.null(output_name), paste0("MOFA_", data_label, ".pptx"), output_name)
print(ppt, target = outfile)
message(paste("PowerPoint saved as", outfile))
}
# Training wrapper
run_mofa_analysis <- function(data_list, n_factors = 2, feature_names = NULL, use_basilisk = TRUE) {
mofa_data <- if (!is.null(feature_names)) {
MOFA2::create_mofa(data_list, feature_names = feature_names)
} else {
MOFA2::create_mofa(data_list)
}
data_opts <- MOFA2::get_default_data_options(mofa_data)
data_opts$scale_views   <- FALSE
data_opts$scale_groups  <- TRUE
data_opts$center_groups <- TRUE
model_opts <- MOFA2::get_default_model_options(mofa_data)
model_opts$num_factors <- n_factors
train_opts <- MOFA2::get_default_training_options(mofa_data)
train_opts$maxiter <- 1000
train_opts$convergence_mode <- "slow"
train_opts$seed <- 123
mofa_obj <- MOFA2::prepare_mofa(
object           = mofa_data,
data_options     = data_opts,
model_options    = model_opts,
training_options = train_opts
)
# If using reticulate and a stored env, politely activate it for this call
if (identical(backend$method, "reticulate") &&
!is.null(backend$envname) &&
requireNamespace("reticulate", quietly = TRUE)) {
try(reticulate::use_condaenv(backend$envname, required = FALSE), silent = TRUE)
}
outfile <- tempfile(fileext = ".hdf5")
suppressWarnings(MOFA2::run_mofa(mofa_obj, outfile, use_basilisk = use_basilisk))
}
utils::data("CLL_data", package = "MOFAdata", envir = environment())
# Keep 2 views for speed; coerce, clean, and ensure dimnames
view_ids  <- c(2, 3)
CLL_small <- get("CLL_data", envir = environment())[view_ids]
cll <- lapply(CLL_small, function(x) {
x <- as.matrix(x)
x[is.na(x)] <- 0
if (is.null(rownames(x))) rownames(x) <- paste0("F", seq_len(nrow(x)))
if (is.null(colnames(x))) colnames(x) <- paste0("S", seq_len(ncol(x)))
x
})
names(cll) <- names(CLL_small)
if (!requireNamespace("MOFAdata", quietly = TRUE))
stop("Package MOFAdata is required for 'real_world' demo.")
if (!requireNamespace("MOFAdata", quietly = TRUE))
utils::data("CLL_data", package = "MOFAdata", envir = environment())
library(MOFAdata)
library(mofadata)
utils::data("CLL_data", package = "MOFAdata", envir = environment())
devtools::document()
devtools::build()
devtools::document()
devtools::build()
devtools::document()
devtools::test()
devtools::check()
devtools::document()
devtools::build()
devtools::document()
devtools::build()
devtools::document()
devtools::build()
devtools::document()
devtools::build()
devtools::document()
devtools::build()
ascii_escape_file <- function(path) {
esc <- function(s) {
cps <- utf8ToInt(s)
paste0(vapply(cps, function(i) {
if (i <= 0x7F) intToUtf8(i)
else if (i <= 0xFFFF) sprintf("\\u%04X", i)
else sprintf("\\U%08X", i)
}, character(1L)), collapse = "")
}
x <- readLines(path, warn = FALSE, encoding = "UTF-8")
x2 <- vapply(x, esc, character(1L))
writeLines(x2, path, useBytes = TRUE)
invisible(path)
}
# Escape ONLY this file first:
ascii_escape_file("R/demo_multiomics_analysis.R")
# Verify all clear:
tools::showNonASCIIfile("R/demo_multiomics_analysis.R")  # should print nothing
ascii_escape_file("R/demo_multiomics_analysis.R")
tools::showNonASCIIfile("R/demo_multiomics_analysis.R")  #
devtools::document()
devtools::build()
devtools::document()
devtools::build()
devtools::document()
devtools::build()
